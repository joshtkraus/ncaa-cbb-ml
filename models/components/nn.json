{"2": {"num_layers": 1, "units_0": 96, "activation_0": "tanh", "batch_norm_0": false, "dropout_0": 0.41638849326004784, "optimizer": "adam", "learning_rate": 0.0031668452209577804, "batch_size": 64}, "3": {"num_layers": 1, "units_0": 224, "activation_0": "tanh", "batch_norm_0": true, "dropout_0": 0.69719474860052, "optimizer": "sgd", "learning_rate": 0.04795764350320369, "batch_size": 16}, "4": {"num_layers": 1, "units_0": 128, "activation_0": "tanh", "batch_norm_0": true, "dropout_0": 0.4828583839294488, "optimizer": "sgd", "learning_rate": 0.023198689150972746, "batch_size": 32}, "5": {"num_layers": 2, "units_0": 192, "activation_0": "relu", "batch_norm_0": true, "dropout_0": 0.8296082334834909, "units_1": 64, "activation_1": "tanh", "batch_norm_1": false, "dropout_1": 0.6523089125276519, "optimizer": "sgd", "learning_rate": 0.06305267004045909, "batch_size": 32}, "6": {"num_layers": 1, "units_0": 160, "activation_0": "relu", "batch_norm_0": false, "dropout_0": 0.05358793242450337, "optimizer": "sgd", "learning_rate": 0.02571292194486563, "batch_size": 32}, "7": {"num_layers": 1, "units_0": 224, "activation_0": "tanh", "batch_norm_0": false, "dropout_0": 0.11294735065500752, "optimizer": "adam", "learning_rate": 0.0013546579912889947, "batch_size": 32}}